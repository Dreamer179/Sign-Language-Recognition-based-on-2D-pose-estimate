\chapter{XÂY DỰNG MẠNG NEURON NHẬN DẠNG NGÔN NGỮ KÝ HIỆU}
\label{s:DNN}
Trong chương 3, thuật toán ước tính tư thế khung xương đã được trình bày chi tiết về lý thuyết và phương pháp xử lý áp dụng thuật toán. Ta thấy rằng phương pháp này hỗ trợ rất tốt cho việc ước tính nh anhtư thế khung xương trong xử lý thời gian thực. Trong chương 4 này, luận văn sẽ trình bày về đề xuất mô hình mạng DNN lấy đầu vào là toạ độ khung xương được ước tính và nhận dạng cử chỉ thời gian thực. Nội dụng chương trình bày cấu trúc mạng neural network đề xuất, cách thu thập và xử lý dữ liệu cũng như sơ đồ hoạt động chương trinh.
\section{Tổng quan}
Một từ ngữ trong bộ ngôn ngữ ký hiệu của người khiếm thính sẽ được thể hiện bằng một loạt các cử chỉ theo thời gian. Tuy nhiên, khi xem xét các hành động của con người nhằm tìm ra một cấu trúc nhất quán và có thể tạo thành mô hình thì gặp các vấn đề phức tạp sau:

$\bullet$ Các từ ngữ ký hiệu không có một cấu trúc hay quy luật nào như chữ viết và tiếng nói. Đối với chữ viết và tiếng nói các dựa trên các chữ cái, dấu câu và âm tiết. Do vậy chỉ cần nhận diện các thành phần đơn vị của nó. Đối với ngôn ngữ ký hiệu, mỗi một từ ngữ sẽ có một cử chỉ khác nhau và các cử chỉ đó không liên quan đến nhau. Do vậy để nhận diện được ngôn ngữ ký hiệu, cần phải nhận diện từng từ riêng biệt.

$\bullet$ Để diễn đạt ngôn ngữ của người khiếm thính. Số lượng từ ngữ trong bộ ngôn ngữ ký hiệu sẽ rất nhiều, lên đến hàng trăm ngàn từ. Do vậy không thể xem xét nhận diện tất cả các từ ngữ đó được.

$\bullet$ Với việc ước tính tọa độ khung xương trong không gian 2D. Các hành động của con người có thể giống nhau, tuy nhiên nếu việc quan sát hoặc camera quan sát nằm ở vị trí khác nhau, hướng, độ cao,... đều ảnh hưởng đến khả năng nhận diện hành động của con người.


$\bullet$ Ngôn ngữ ký hiệu của người khiếm thính, để diễn đạt được không những cần phải thể hiện qua tư thế mà còn cần phải thể hiện qua cử động bàn tay và nét mặt. Đối với phạm vi luận văn này chỉ hướng đến phân tích về tư thế con người.

$\bullet$ Nếu một phần cơ thể bị che khuất bởi các vật thể thì việc xác định hành động của con người sẽ gặp khó khăn hơn rất nhiều so với trường hợp không bị che khuất, phạm vi luận văn không xem xét đến vấn đề này. Tuy nhiên đây là một điểm cần xem xét đến để có thể hoàn thiện hệ thống nhận diện cử chỉ trong tương lai.

Đố với những vấn đề trên, mô hình nhận dạng được xây dựng có đặc điểm như sau. Trong các từ ngữ ký hiệu, nhận thấy có những từ ngữ phải thể hiện qua nhiều tư thế, cử chỉ tay liên tiếp nhau. Nhưng có những từ chỉ cần đưa về một tư thế hoặc một tư thế đó nhưng có sự dao động của một số bộ phận. Trong phạm vi luận văn này tập trung nhận dạng những từ ngữ với tư thế cố định đó. Mô hình xây dựng sẽ nhận dạng 16 cử chỉ với tư thế cố định và các cử chỉ tương đối khác nhau: (\textbf{Xin chào, Tôi, thành phố, vui vẻ, ẵm em, Sài Gòn, Vĩnh Long, đi bộ, mùa màng, đói bụng, yêu, ăn, biểu quyết, đứng yên, hẹp, rộng}).

\section{Thu thập dữ liệu}
Dữ liệu đầu vào là tọa độ của 18 khớp xương được dự đoán từ mạng ước tính tư thế khung xương từ chương 3. Các khớp xương được dự đoán từ mạng được đánh số thứ tự từ 0 tới 17. Các khớp xương cụ thể được thể hiện trong bảng \ref{table:joints} và trong hình \ref{fig:joints}.


\begin{table}[h]
\caption{Các khớp xương được dự đoán từ mạng ước tính khung xương}
\label{table:joints}
\centering
\begin{center}
\begin{tabular}{|c|c||c|c|} 
 \hline
Số thứ tự khớp xương  & Vị trí & Số thứ tự khớp xương & Vị trí\\
 \hline
 0 & Mũi & 9 & Đầu gối phải\\
 \hline 
 1 & Cổ & 10 & Cổ chân phải\\
 \hline 
 2 & Vai phải & 11 & Hông trái\\
 \hline
 3 & Khủy tay phải & 12 & Đầu gối trái \\
 \hline 
 4 & Cổ tay phải & 13 & Cổ chân trái \\
 \hline
 5 & Vai trái & 14 & Mắt phải \\
 \hline
 6 & Khủy trái & 15 & Mắt trái \\
 \hline
 7 & Cổ tay trái & 16 & Tai phải \\
 \hline
 8 & Hông phải & 17 & Tai trái\\
 \hline
\end{tabular}
\end{center}
\end{table}

\FloatBarrier
\begin{figure}[htp]
\begin{center}
\includegraphics[scale=0.6]{chap4/c4_figs/joints_order.png}
\end{center}
\caption{Sơ đồ khớp xương xuất ra từ mạng ước tính tư thế}
\label{fig:joints}
\end{figure}
\FloatBarrier

Đầu tiên người thu thập dữ liệu đứng trước camera, thực hiện hành động thể hiện từ cần huấn luyện. Chương trình thu thập dữ liệu sẽ xuất ra tọa độ khung xương sau khi xử lý qua mạng pose estimate. Sau đó lưu các tọa độ khớp xương cùng với nhãn của hành động vào file "data.csv" để sau đó đưa vào huấn luyện. Hình \ref{fig:collect_data} thể hiện quá trình khi thu thập dữ liệu.

Để đảm bảo tính đa dạng của dữ liệu, các SJM được thu thập từ 5 người cao thấp khác nhau. Mỗi ký từ ngữ ký hiệu sẽ thu thập 800 SJM  để huấn luyện và 400 SJM để đánh giá mô hình.

\FloatBarrier
\begin{figure}[htp]
\begin{center}
\includegraphics[scale=0.4]{chap4/c4_figs/collect_data.png}
\end{center}
\caption{Giao diện thu thập dữ liệu(khi bắt đầu ghi dữ liệu)}
\label{fig:collect_data}
\end{figure}
\FloatBarrier

\newpage

%\FloatBarrier
%\begin{figure}[htp]
%\begin{center}
%\includegraphics[scale=0.35]{chap4/c4_figs/collect_data1.png}
%\end{center}
%\caption{Giao diện thu thập dữ liệu (khi đã thu thập đủ dữ liệu)}
%\label{fig:collect_data1}
%\end{figure}
%\FloatBarrier

\section{Xử lý dữ liệu đầu vào}
Dữ liệu sau khi thu thập ban đầu bao gồm tất cả tọa độ các khớp xương ứng các hành động cần nhận dạng. Tuy nhiên khi huấn luyện bộ nhận diện ngôn ngữ ký hiệu ta cần phải xử lý lại dữ liệu khớp xương đã thu thập được. Quá trình xử lý trải qua 2 phần: Loại bỏ các phần khớp xương dư thừa, sau đó chuẩn hóa lại các vector SJM.

\subsection{Loại bỏ các phần SJM dư thừa}
Ngôn ngữ ký hiệu với đặc trưng là sự phối hợp phần trên cơ thể với hai tay để diễn đạt từ ngữ mong muốn. Do đó việc xem xét đến các khớp xương phần dưới cơ thể là không cần thiết. Phần xử lý này, đề tài đã loại bỏ các tọa độ SJM dư thừa, chỉ giữ lại 10 điểm khớp xương cần thiết cho việc nhận diện: \textbf{Mũi, Cổ, Vai trái, khuỷu tay trái, Cổ tay trái, Vai phải, Khủy tay phải, Cổ tay phải, hông phải và hông trái} như thể hiện trong hình \ref{fig:joints} và bảng \ref{table:joints_choose}

\FloatBarrier
\begin{table}[h]
\caption{Các khớp xương được giữ lại}
\label{table:joints_choose}
\centering
\begin{center}
\begin{tabular}{|c|c||c|c|} 
 \hline
Số thứ tự khớp xương  & Vị trí \\
 \hline
 0 & Mũi\\
 \hline 
 1 & Cổ\\
 \hline 
 2 & Vai phải\\
 \hline
 3 & Khủyu tay phải \\
 \hline 
 4 & Cổ tay phải\\
 \hline
 5 & Vai trái\\
 \hline
 6 & Khủyu tay trái\\
 \hline
 7 & Cổ tay trái\\
 \hline
 8 & Hông phải\\
 \hline
 11 & Hông trái\\
 \hline
\end{tabular}
\end{center}
\end{table}


\begin{figure}[htp]
\begin{center}
\includegraphics[scale=0.11]{chap4/c4_figs/joints_choose_1.png}
\end{center}
\caption{Sơ đồ một SJM sau khi loại bỏ các phần không cần thiết}
\label{fig:joints}
\end{figure}
\FloatBarrier

\newpage

\subsection{Chuẩn hóa SJM để phân loại đặc trưng}

Dựa vào dữ liệu thu thập được, ta có thể nhận thấy hai điều sau:
\begin{itemize}
\item tùy vào vị trí camera, khoảng cách từ camera đến người được quan sát sẽ làm thay đổi giá trị của các vector khung xương SJM. Hình \ref{fig:kq_skeleton} từ kết quả chương 3 có thể thấy kích thước các SJM của người ở xa camera sẽ nhỏ hơn so với người ở gần.
\item Nếu góc để camera không được đặt thẳng đứng theo chiều dọc khiến cho hình ảnh người đưa vào không thẳng đứng. Các SJM ước tính ra cũng sẽ khác với khi đặt camera thẳng.
\end{itemize}

Nếu đưa dữ liệu các SJM này vào huấn luyện thì phải cần rất nhiều dữ liệu cho các trường hợp nêu trên. Do đó ta cần phải sử dụng phương pháp chuẩn hóa dữ liệu các SJM, đưa các vector đặc trưng SJM về theo chiều thẳng đứng và cùng kích cỡ thì dữ liệu đưa vào huấn luyện sẽ có thể giảm bớt đi và từng cử chỉ mới có cùng những đặc trưng giống nhau.
\\[2cm]
\begin{itemize}
\item[$\square$] Phương pháp chuẩn hóa trong đề tài được áp dụng như sau:
\end{itemize}
\begin{itemize}
\item Đầu tiên, ta sử dụng các dữ liệu ban đầu - raw data cho việc gán đặc trưng. Để dễ hình dung, ta đặt tên các SJM-J trong SJM cần xét là các điểm từ A $\rightarrow$ J. Xem xét bảng vị trí của các SJM-J của SJM đặc trưng từ bảng \ref{BangSJM}.
\end{itemize}

\begin{table}[htp]
\centering
\caption{Đặt tên các SJM từ $\rightarrow$ J}
\begin{tabular}{|c|c|c|}
\hline 
 Điểm SJM-J & Tên SJM-J & $(x_i; y_i) $\\ 
\hline 
A & Mũi  & $(x_A; y_A)$ \\
\hline 
B & Cổ & $(x_B; y_B)$ \\ 
\hline 
C & Vai phải  & $(x_C; y_C)$ \\ 
\hline 
D & Khủy tay phải & $(x_D; y_D)$ \\ 
\hline 
E & Cổ tay phải & $(x_E; y_E)$ \\ 
\hline
F & Vai trái & $(x_F; y_F)$ \\ 
\hline
G & Khuỷu tay trái & $(x_G; y_G)$ \\ 
\hline
H & Cổ tay trái & $(x_H; y_H)$ \\ 
\hline
I &  Hông phải & $(x_I; y_H)$ \\
\hline
J & Hông trái & $(x_J; y_J)$ \\ 
\hline
\textbf{K} & \textbf{Cột sống gốc} & $\mathbf{(x_K; y_K)}$ \\ 
\hline
\end{tabular} 
\label{BangSJM}
\end{table}

Mục tiêu đặt ra là đưa các SJM đều xoay theo chiều thẳng đứng với kích thước các SJM sẽ đưa về kích cỡ chuẩn hóa. Để làm được điều này, ta ước lượng thêm một điểm SJM-J nữa gọi là cột sống gốc (root spine) đánh dấu là điểm K. SJM-J này được tính bằng cách lấy trung bình cộng của 2 SJM-J "hông phải" và "hông trái":

\begin{equation}
K = (x_K; y_K) = (\frac{x_I+x_J}{2};\frac{y_I+y_J}{2})
\end{equation}

\begin{itemize}
\item Sau đó đưa vector nối 2 điểm cổ và cột sống gốc trở thành vector đơn vị - unit vector. Việc này sẽ khiến cho các SJM sẽ đưa về cùng một kích thước :
\end{itemize}

\begin{equation}
v_\textit{neck-root\_spine} = (0;1)
\end{equation}

Công thức để tính toán vị trí mới, chuẩn hóa của khớp A (tương tự với các khớp còn lại):

\begin{equation}
{y_{A'}} = \frac{1}{2}\left( {{{\left( {\frac{{AB}}{{BK}}} \right)}^2} - {{\left( {\frac{{AK}}{{BK}}} \right)}^2} + 1} \right) = \frac{{A{B^2} - A{K^2} + B{K^2}}}{{2B{K^2}}}
\end{equation}

Một hàm tính toán được thêm vào để dễ dàng lập trình hơn:
\begin{equation}
{f_{BK}}(x,y) = ({y_B} - {y_K})x - ({x_B} - {x_K})y - ({y_B} - {y_K}){x_K} + ({x_B} - {x_K}){y_K}
\end{equation}

với đặc điểm:\\

$\bullet \text{   }  f_\text{BK}(x_A,y_A > 0$: điểm A nằm phía trên đoạn thẳng BK\\

$\bullet \text{   }  f_\text{BK}(x_A,y_A)< 0$: điểm A nằm phía dưới đoạn thẳng BC\\

$\bullet \text{   } f_\text{BC}(x_A,y_A)= 0$: điểm A nằm trên đường thẳng chứa đoạn thẳng BK\\

Hàm BC không có ý nghĩa hình học tuy nhiên lại có ý nghĩa về mặt đại số, dựa vào hàm kết quả vị trí tương đối giữa điểm A và BK, ta có thể tìm được giá trị của $x_\text{A'}$ :

\begin{equation}
{x_{A'}} = {\mathop{\rm sgn}} ({f_{BK}}({x_A},{y_A})\sqrt {{{\left( {\frac{{AK}}{{BK}}} \right)}^2} - {y_{A'}}^2} 
\end{equation}

Tương tự với các vị trí $C', D', E', F', G' , H' , I' , J'$ với điểm gốc là B,C. Từ đó ta có tọa độ vị trí các SJM-J sau khi chuẩn hóa:\*

\begin{tabular}{c c c}
$A(x_A; y_A)$ & $\Rightarrow$ & $A'(x_{A'}; y_{A'})$ \\ 
$B(x_B; y_B)$ & $\Rightarrow$ & $B'(0;1)$ \\ 
$C(x_C; y_C)$ & $\Rightarrow$ & $C'(x_{C'}; y_{C'})$ \\ 
$D(x_D; y_D)$ & $\Rightarrow$ & $D'(x_{D'}; y_{D'})$ \\ 
$E(x_E; y_E)$ & $\Rightarrow$ & $E'(x_{E'}; y_{E'})$ \\ 
$F(x_F; y_F)$ & $\Rightarrow$ & $F'(x_{F'}; y_{F'})$ \\ 
$G(x_G; y_G)$ & $\Rightarrow$ & $G'(x_{G'}; y_{G'})$ \\ 
$H(x_H; y_H)$ & $\Rightarrow$ & $H'(x_{A'}; y_{A'})$ \\ 
$I(x_I; y_I)$ & $\Rightarrow$ & $I'(x_{I'}; y_{I'})$ \\ 
$J(x_J; y_J)$ & $\Rightarrow$ & $J'(x_{J'}; y_{J'})$ \\ 
$K(x_K; y_K)$ & $\Rightarrow$ & $K'(0;0)$ \\ 
\end{tabular} \*

Sau khi tìm được $(A', B', C', D', E', F', G' , H' , I' , J', K')$ ta có được SJM mới đã chuẩn hóa như hình \ref{fig:skeleton_2}.

\FloatBarrier
\begin{figure}[htp]
\begin{center}
\includegraphics[scale=0.14]{chap4/c4_figs/skeleton_2.png}
\end{center}
\caption{SJM sau khi đã được chuẩn hóa}
\label{fig:skeleton_2}
\end{figure}
\FloatBarrier

Sau khi loại bỏ các phần thừa và chuẩn hóa hết bộ dữ liệu các SJM, ta được các SJM với tọa độ các điểm khớp xương được chuẩn hóa thể hiện trong hình \ref{fig:skeleton_normalize}.
\FloatBarrier
\begin{figure}[htp]
\begin{center}
\includegraphics[scale=0.28]{chap4/c4_figs/datajoint.png}
\end{center}
\caption{Dữ liệu khớp xương sau khi đã được chuẩn hóa}
\label{fig:skeleton_normalize}
\end{figure}
\FloatBarrier

\section{Cấu trúc mạng neural network xây dựng}
Từ dữ liệu đầu vào là một ảnh RGB, qua bước phát hiện khung xương với mạng CNN và các bước chuẩn hóa, loại bỏ khớp xương thừa, dữ liệu cần phân loại gần như đã lấy ra hết đặc trưng cần tìm và giảm số chiều đến tối đa. Do đó mạng DNN cần dùng để phân loại các từ ngôn ngữ ký hiệu chỉ cần một cấu trúc vừa phải và giảm thiểu số trọng số đến tối đa.

\begin{itemize}
\item Input: Mạng với đầu vào là 20 nodes ứng với tọa độ của 10 khớp xương (mỗi khớp là 2 tọa độ x, y).
\item Hidden layer: Là các lớp Fully connected (Dense) và Normalization xen kẽ nhau.
\item Output: Với softmax với 16 nodes ứng với 16 từ ngữ nhận diện được.
\end{itemize}
Cụ thể các thông số và cấu trúc được thể hiện trong hình \ref{fig:model_params}.

\FloatBarrier
\begin{figure}[htp]
\begin{center}
\includegraphics[scale=1.2]{chap4/c4_figs/model_param.png}
\end{center}
\caption{Các thông số của mạng DNN}
\label{fig:model_params}
\end{figure}
\FloatBarrier


Model sử dụng khá nhiều lớp Batch Normalization. Về lý thuyết toán thì layer này có tác dụng trong 2 việc đó là:
\begin{itemize}
\item Tránh gradient tiến về 0 sẽ chẳng biết là đi lên hay xuống.
\item Gradient quá lớn khiến các tham số không thể tối ưu được (loss sẽ nhảy lung tùng).
\end{itemize}
Cụ thể là nó giúp chuẩn hóa dữ liệu về 1 khoảng (0,1).

\section{Huấn luyện mạng}
Mạng được huấn luyện theo thuật toán Stochastic Gradient Descent (SGD) là một biến thể của Gradient Descent. Cụ thể ta sẽ tìm hiểu về nó qua các phần dưới dây.

\subsection{Gradient Descent}
Trong Machine Learning nói riêng và Toán Tối Ưu nói chung, chúng ta thường xuyên phải tìm giá trị nhỏ nhất (hoặc đôi khi là lớn nhất) của một hàm số nào đó. Ví dụ như các hàm mất mát trong hai bài Linear Regression và K-means Clustering. Nhìn chung, việc tìm global minimum của các hàm mất mát trong Machine Learning là rất phức tạp, thậm chí là bất khả thi. Thay vào đó, người ta thường cố gắng tìm các điểm local minimum, và ở một mức độ nào đó, coi đó là nghiệm cần tìm của bài toán.

Các điểm local minimum là nghiệm của phương trình đạo hàm bằng 0. Nếu bằng một cách nào đó có thể tìm được toàn bộ (hữu hạn) các điểm cực tiểu, ta chỉ cần thay từng điểm local minimum đó vào hàm số rồi tìm điểm làm cho hàm có giá trị nhỏ nhất. Tuy nhiên, trong hầu hết các trường hợp, việc giải phương trình đạo hàm bằng 0 là bất khả thi. Nguyên nhân có thể đến từ sự phức tạp của dạng của đạo hàm, từ việc các điểm dữ liệu có số chiều lớn, hoặc từ việc có quá nhiều điểm dữ liệu.

Hướng tiếp cận phổ biến nhất là xuất phát từ một điểm mà chúng ta coi là gần với nghiệm của bài toán, sau đó dùng một phép toán lặp để tiến dần đến điểm cần tìm, tức đến khi đạo hàm gần với 0. Gradient Descent (viết gọn là GD) và các biến thể của nó là một trong những phương pháp được dùng nhiều nhất.

Các bước quan trọng của thuật toán Gradient Descent như sau:
\begin{itemize}
\item Dự đoán một điểm khởi tạo $\theta = \theta_0$.
\item Cập nhật $\theta$ đến khi đạt được kết quả chấp nhận được: 
$$\theta = \theta - \eta \nabla_{\theta}J(\theta)$$
với $\nabla_{\theta}J(\theta)$ là đạo hàm của hàm mất mát tại $\theta$
\end{itemize}

\textbf{Gradient dưới góc nhìn vật lý:}

Thuật toán GD thường được ví với tác dụng của trọng lực lên một hòn bi đặt trên một mặt có dạng như hình một thung lũng giống như hình \ref{fig:gradient} dưới đây. Bất kể ta đặt hòn bi ở A hay B thì cuối cùng hòn bi cũng sẽ lăn xuống và kết thúc ở vị trí C.

\FloatBarrier
\begin{figure}[htp]
\begin{center}
\includegraphics[scale=0.06]{chap4/c4_figs/momentum.png}
\end{center}
\caption{So sánh Gradient Descent với các hiện tượng vật lý}
\label{fig:gradient}
\end{figure}
\FloatBarrier

\centerline{(Nguồn: "Machine learning cơ bản" - Vũ Hữu Tiệp)}
Tuy nhiên, nếu như bề mặt có hai đáy thung lũng như Hình \ref{fig:gradient}b thì tùy vào việc đặt bi ở A hay B, vị trí cuối cùng của bi sẽ ở C hoặc D. Điểm D là một điểm local minimum chúng ta không mong muốn.

Nếu suy nghĩ một cách vật lý hơn, vẫn trong Hình \ref{fig:gradient}b, nếu vận tốc ban đầu của bi khi ở điểm B đủ lớn, khi bi lăn đến điểm D, theo đà, bi có thể tiếp tục di chuyển lên dốc phía bên trái của D. Và nếu giả sử vận tốc ban đầu lớn hơn nữa, bi có thể vượt dốc tới điểm E rồi lăn xuống C như trong Hình \ref{fig:gradient}c. Đây chính là điều chúng ta mong muốn.

\subsection{Stochastic Gradient Descent}
Trong thuật toán này, tại 1 thời điểm, ta chỉ tính đạo hàm của hàm mất mát dựa trên chỉ một điểm dữ liệu $\mathbf{x_i}$ rồi cập nhật 
$\theta$ dựa trên đạo hàm này. Việc này được thực hiện với từng điểm trên toàn bộ dữ liệu, sau đó lặp lại quá trình trên. Thuật toán rất đơn giản này trên thực tế lại làm việc rất hiệu quả.

Mỗi lần duyệt một lượt qua tất cả các điểm trên toàn bộ dữ liệu được gọi là một epoch. Với GD thông thường thì mỗi epoch ứng với 1 lần cập nhật $\theta$, với SGD thì mỗi epoch ứng với $\mathbf{N}$ lần cập nhật $\mathbf{\theta}$ với $\mathbf{N}$ là số điểm dữ liệu. Nhìn vào một mặt, việc cập nhật từng điểm một như thế này có thể làm giảm đi tốc độ thực hiện 1 epoch. Nhưng nhìn vào một mặt khác, SGD chỉ yêu cầu một lượng epoch rất nhỏ (thường là 10 cho lần đầu tiên, sau đó khi có dữ liệu mới thì chỉ cần chạy dưới một epoch là đã có nghiệm tốt). Vì vậy SGD phù hợp với các bài toán có lượng cơ sở dữ liệu lớn (chủ yếu là Deep Learning mà chúng ta sẽ thấy trong phần sau của blog) và các bài toán yêu cầu mô hình thay đổi liên tục, tức online learning.

\textbf{Thứ tự lựa chọn điểm dữ liệu:}
Một điểm cần lưu ý đó là: sau mỗi epoch, chúng ta cần shuffle (xáo trộn) thứ tự của các dữ liệu để đảm bảo tính ngẫu nhiên. Việc này cũng ảnh hưởng tới hiệu năng của SGD.

Một cách toán học, quy tắc cập nhật của SGD là:
$$\theta = \theta - \eta \nabla_{\theta} J(\theta; \mathbf{x}_i; \mathbf{y}_i)$$
trong đó $J(\theta; \mathbf{x}_i; \mathbf{y}_i)$ là hàm mất mát với chỉ 1 cặp điểm dữ liệu (input, label) là $(\mathbf{x}_i, \mathbf{y}_i)$. Ngoài ra, chúng ta hoàn toàn có thể áp dụng các thuật toán tăng tốc GD như Momentum, AdaGrad,… vào SGD.

\subsection{Điều kiện dừng}
Trong thực nghiệm, có một vài phương pháp như dưới đây để xác định khi nào cần dừng số vòng lặp khi huấn luyện:
\begin{itemize}
\item Giới hạn số vòng lặp: đây là phương pháp phổ biến nhất và cũng để đảm bảo rằng chương trình chạy không quá lâu. Tuy nhiên, một nhược điểm của cách làm này là có thể thuật toán dừng lại trước khi đủ gần với nghiệm.
\item So sánh gradient của nghiệm tại hai lần cập nhật liên tiếp, khi nào giá trị này đủ nhỏ thì dừng lại. Phương pháp này cũng có một nhược điểm lớn là việc tính đạo hàm đôi khi trở nên quá phức tạp (ví dụ như khi có quá nhiều dữ liệu), nếu áp dụng phương pháp này thì coi như ta không được lợi khi sử dụng SGD và mini-batch GD.
\item So sánh giá trị của hàm mất mát của nghiệm tại hai lần cập nhật liên tiếp, khi nào giá trị này đủ nhỏ thì dừng lại. Nhược điểm của phương pháp này là nếu tại một thời điểm, đồ thị hàm số có dạng bẳng phẳng tại một khu vực nhưng khu vực đó không chứa điểm local minimum (khu vực này thường được gọi là saddle points), thuật toán cũng dừng lại trước khi đạt giá trị mong muốn.
\item Trong SGD và mini-batch GD, cách thường dùng là so sánh nghiệm sau một vài lần cập nhật.
\end{itemize}


\subsection{Áp dụng vào bài toán}
Với bộ dữ liệu của bài toán nhận dạng ngôn ngữ ký hiệu, dữ liệu là các SJM được thu thập từ trước.

Khi training một model, luận văn chia bộ dữ liệu thu thập được thành hai bộ riêng biệt:
\begin{itemize}
\item Đầu tiên là bộ dữ liệu dùng để huấn luyện. Bộ dữ liệu huận luyện được chia thành training dataset và validation dataset và có sự hòa trộn dữ liệu giữa 2 bộ này giữa các epoch trong quá trình huấn luyện. Training dataset được sử dụng để huấn luyện mô hình, tuy nhiên, độ chính xác mà mô hình đạt được trên training set là không đáng tin cậy để đánh giá độ chính xác của mô hình. Validation dataset được sử dụng để đo lường mức độ hiệu quả của models trên các ví dụ không phải là một phần của training dataset. Các số liệu được tính toán trên validation dataset có thể được sử dụng để điều chỉnh các hyperparameters của model. Tuy nhiên, mỗi khi đánh giá validation dataset và đưa ra quyết định dựa trên những điểm số đó, mô hình chia sẻ thông tin từ validation dataset vào model. Các đánh giá càng nhiều, càng có nhiều thông tin bị chia sẻ. Vì vậy, việc huấn luyện có thể kết thúc việc ghi đè lên validation dataset và một lần nữa, validation score sẽ không đáng tin cậy để dự đoán hành vi của model trong thế giới thực.

\item Test dataset là bộ dữ liệu thứ hai, bộ dữ liệu này hoàn toàn riêng biệt so với 2 bộ dữ liệu trước. Test dataset không được sử dụng trong việc huấn luyện mà được sử dụng để đo lường mức độ hiệu quả của model trên các ví dụ không nhìn thấy trước đó. Bộ dữ liệu này chỉ được sử dụng khi đã hoàn tất việc huấn luyện trên 2 bộ dữ liệu kia.
\end{itemize}

Dữ liệu sẽ được chia ra thành 2 tập gồm: train data (dữ liệu để huấn luyện) và validation data (dữ liệu đánh giá) với tỷ lệ 80 và 20 và có sự xáo trộn dữ liệu giữa 2 bộ sau mỗi epoch. Nghĩa là với mỗi hành động (data gồm 800 SJM) sẽ có khoảng 640 SJM để huấn luyện và khoảng 160 SJM để đánh giá. Test data gồm khoảng 400 SJM đối với mỗi ký để kiểm tra và đánh giá mô hình. Các đánh giá trong chương 5 sẽ đánh giá trên bộ dữ liệu này của bài toán.
Áp dụng thuật toán SGD, với các thông số ban đầu được khởi tạo trước khi huấn luyện như sau:
\begin{itemize}
\item epoch: 50
\item learning rate: 0.001
\item batch$\_$size : 32
\item iterations : 400
\end{itemize}
Trong quá trình huấn luyện, luận văn sử dụng phương pháp lưu lại checkpoint. Cách thức hoạt động của phương pháp này là sau mỗi epoch, accuracy trên tập test của model hiện tại được so sánh với accuracy của model trước đó. Nếu nó lớn hơn thì trọng số của mô hình sẽ được cập nhật theo trọng số mới nhất. Nếu nhỏ hơn, trọng số của mô hình trước đó vẫn được giữ lại cho đến khi accuracy khác cao hơn. Phương pháp này giúp tìm được model tối ưu nhất với accuracy cao nhất có thể.
Sau 50 epoch, ta có kết quả về độ chính xác(accuracy) và sai số (loss) trên tập train và tập test như sau:
\FloatBarrier
\begin{figure}[htp]
\begin{center}
\includegraphics[scale=1]{chap4/c4_figs/train_val_acc.png}
\end{center}
\caption{Accurracy của tập train và validate}
\label{fig:pipelineS}
\end{figure}
\FloatBarrier

\FloatBarrier
\begin{figure}[htp]
\begin{center}
\includegraphics[scale=1]{chap4/c4_figs/train_val_l.png}
\end{center}
\caption{Loss của tập train và validate}
\label{fig:pipelineS}
\end{figure}
\FloatBarrier

Từ biểu đồ accuracy và loss của mô hình, có thể thấy mô hình đã học được rất tốt. Kể từ epoch thứ 10, mô hình đã đạt được accuracy cao và loss giảm xuống thấp. Đường biểu diễn của 2 tập đối với accuracy và loss đi sát nhau có thể phần nào dự đoán được mô hình không bị overfiting. 

\section{Kết quả}

Nhận thấy kết quả mô hình đã học được rất tốt với thuật toán này. Với kết quả cuối cùng:
\begin{itemize}
\item Train Accuracy: 0.9998
\item Validation Accuracy: 0.9996
\item Train Loss: 0.0022
\item Validation Loss    : 0.0029
\end{itemize}

Dựa vào những thông số trên có thể thấy kết quả sau khi huấn luyện mô hình khá tốt. Nhưng để áp dụng mô hình vào thực tế được, ta cần phải thử nghiệm và đánh giá bằng nhiều phương pháp trên tập dữ liệu mới. Trong chương 5 luận văn sẽ trình bày về cách thức thử nghiệm, đánh giá mô hình cũng như xây dựng phần mềm ứng dụng từ mô hình.  Chương 4 tiếp theo luận văn sẽ trình bày giải thuật Deep Sort dùng để theo dõi những người trong khung ảnh, từ đó có thể áp dụng nhận diện dc chuỗi các ký tự của ngôn ngữ ký hiệu mà từng người diễn đạt.